<<<<<<< HEAD
Procesamiento de Lenguaje Natural - Sistema de AnÃ¡lisis de Texto
Este proyecto es una aplicaciÃ³n web Django para el anÃ¡lisis de textos utilizando tÃ©cnicas de Procesamiento de Lenguaje Natural (NLP). Incluye tokenizaciÃ³n, cÃ¡lculo de frecuencias, n-gramas y probabilidades condicionales usando el enfoque de MÃ¡xima Verosimilitud (MLE).

ðŸš€ CaracterÃ­sticas
âœ… Subida y procesamiento de archivos de texto

âœ… TokenizaciÃ³n y limpieza de texto

âœ… CÃ¡lculo de frecuencias de palabras

âœ… GeneraciÃ³n de histogramas de frecuencias

âœ… AnÃ¡lisis de n-gramas (unigramas, bigramas, trigramas, etc.)

âœ… CÃ¡lculo de probabilidades condicionales (MLE)

âœ… ComparaciÃ³n con y sin fronteras de oraciÃ³n

âœ… Interfaz web amigable

ðŸ“‹ Requisitos Previos
Python 3.8+

pipenv (entorno virtual)

Git

ðŸ› ï¸ InstalaciÃ³n
1. Clonar el repositorio
bash
git clone https://github.com/aguasCabrerapa0/PROYECTO-PNL.git
cd "Procesamiento de lenguaje natural"
2. Configurar entorno virtual con pipenv
bash
# Instalar pipenv si no lo tienes
pip install pipenv

# Crear entorno virtual e instalar dependencias
pipenv install
3. Instalar datos de NLTK
bash
# Activar el entorno virtual
pipenv shell

# Descargar los datos necesarios de NLTK
python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('stopwords')"
4. Configurar la base de datos
bash
# Aplicar migraciones
python manage.py makemigrations
python manage.py migrate
5. Crear superusuario (opcional)
bash
python manage.py createsuperuser
ðŸš€ EjecuciÃ³n
bash
# Activar el entorno virtual (si no estÃ¡ activo)
pipenv shell

# Ejecutar el servidor de desarrollo
python manage.py runserver
Abrir en el navegador: http://127.0.0.1:8000/

ðŸ“– Uso del Sistema
1. Subir un texto
Haz clic en "Subir nuevo texto"

Completa el tÃ­tulo

Selecciona el archivo de texto

Elige el tipo de n-grama (1-5)

Marca la opciÃ³n "Calcular probabilidades MLE" si deseas anÃ¡lisis avanzado

Haz clic en "Subir y Analizar"

2. Ver resultados
Lista de textos: Muestra todos los textos procesados con sus frecuencias

Probabilidades MLE: Muestra anÃ¡lisis detallado con y sin fronteras de oraciÃ³n

3. AnÃ¡lisis MLE
El sistema calcula:

Probabilidades condicionales usando MÃ¡xima Verosimilitud

ComparaciÃ³n con fronteras de oraciÃ³n (<s> y </s>)

Tablas de frecuencias y probabilidades

EstadÃ­sticas comparativas
=======
# CÃ³mo ejecutar el proyecto (PLN avance 2)

## Requisitos
- Python 3.10+
- (Opcional) pipenv

## Pasos
```bash
cd "/mnt/data/PLN_avance2_extracted/Procesamiento de lenguaje natural"
# Entorno
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt  # instala Django

# Migraciones y arranque
python manage.py migrate
python manage.py runserver
```

Luego abre http://127.0.0.1:8000/

## Limpieza integrada (minÃºsculas, sin puntuaciÃ³n, sin stopwords)
El flujo de carga ahora procesa el archivo de texto y:
- Convierte a minÃºsculas.
- Elimina signos de puntuaciÃ³n (se extraen solo tokens alfabÃ©ticos).
- Elimina stopwords en espaÃ±ol (lista incorporada).
- Calcula frecuencias y llena el modelo `Palabra`.

### DÃ³nde estÃ¡ la lÃ³gica
- `analisis/preprocesamiento.py`: STOPWORDS + funciones `clean_and_filter` y `frequencies`.
- `analisis/views.py`: en `subir_texto`, despuÃ©s de `form.save()` se lee el archivo, se limpia, se tokeniza y se guardan frecuencias.

## VerificaciÃ³n
1) Sube un `.txt` en `/subir/`.
2) Vuelve a la pÃ¡gina principal y confirma que aparecen tokens y frecuencias bajo el tÃ­tulo.
3) De ser necesario, borra `db.sqlite3` para reiniciar datos y repite pruebas.

## Commit sugerido
Si tu proyecto estÃ¡ versionado con Git, ejecuta desde la raÃ­z del proyecto:
```bash
git add analisis/preprocesamiento.py analisis/views.py README_CORRER_PROYECTO.md
git commit -m "Limpieza de texto: minÃºsculas, eliminaciÃ³n de puntuaciÃ³n y stopwords en espaÃ±ol; integraciÃ³n en flujo de carga y guardado de frecuencias"
```

## Tokens y Nube de Palabras
- Se guardan **tokens procesados** (sin puntuaciÃ³n y sin stopwords) en `TextoAnalizado.tokens_json`.
- Se genera una **nube de palabras** por texto y se guarda como imagen en `TextoAnalizado.nube_imagen` (carpeta `media/wordclouds/`).

### Requisitos nuevos
Instala dependencias adicionales:
```bash
pip install -r requirements.txt
```

### Migraciones
Como se agregaron campos al modelo, ejecuta:
```bash
python manage.py makemigrations analisis
python manage.py migrate
```

### Commit sugerido
```bash
git add analisis/models.py analisis/views.py analisis/templates/analisis/lista.html requirements.txt README_CORRER_PROYECTO.md
git commit -m "Tokens procesados y nube de palabras: JSONField e ImageField en TextoAnalizado; generaciÃ³n tras la carga del archivo; plantilla actualizada"
```
>>>>>>> 76182a81822a6aa7a9c45c67f5f91222cbee9ddc
